"""
æµ‹è¯•è·å–æœ€æ–°ç‰ˆæœ¬æ›´æ–°é“¾æ¥çš„åŠŸèƒ½
"""
import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from app.crawlers.lol_official import LOLOfficialCrawler


async def main():
    """æµ‹è¯•çˆ¬è™«åŠŸèƒ½"""
    print("=" * 70)
    print("æµ‹è¯•: è·å–æœ€æ–°ç‰ˆæœ¬æ›´æ–°é“¾æ¥")
    print("=" * 70)
    print()

    crawler = LOLOfficialCrawler()

    try:
        # æµ‹è¯• 1: è·å–æœ€æ–°ç‰ˆæœ¬æ›´æ–°é“¾æ¥
        print("ğŸ” æµ‹è¯• _fetch_news_list() æ–¹æ³•...")
        latest_url = await crawler._fetch_news_list()
        print(f"âœ… è·å–æœ€æ–°é“¾æ¥æˆåŠŸ:")
        print(f"   URL: {latest_url}")
        print()

        # æµ‹è¯• 2: çˆ¬å–è¯¥é“¾æ¥çš„å†…å®¹
        print("ğŸ” æµ‹è¯• fetch_latest_patch_notes() æ–¹æ³•...")
        content = await crawler.fetch_latest_patch_notes()
        print(f"âœ… çˆ¬å–å†…å®¹æˆåŠŸ:")
        print(f"   é•¿åº¦: {len(content)} å­—ç¬¦")
        print(f"   æ¥æº: {crawler.last_url}")
        print()
        print(f"   å‰ 200 å­—ç¬¦é¢„è§ˆ:")
        print(f"   {content[:200]}...")
        print()

        print("=" * 70)
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("=" * 70)

    except Exception as e:
        print()
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)